{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish Diacritisation | YZV 405E NLP Term Project\n",
    "\n",
    "Author: Bora Boyacıoğlu\n",
    "\n",
    "Student ID: 150200310\n",
    "\n",
    "## Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DiacritizationDataset\n",
    "from utils.main_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Datasets\n",
    "\n",
    "We have two datasets: `train` and `test`. We will use the `train` dataset to train our model and the `test` dataset to evaluate the model. Firstly, open these datasets using the defined Dataset classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset.\n",
    "train_data = DiacritizationDataset('data/train.csv', type='train')\n",
    "\n",
    "# Test dataset.\n",
    "test_data = DiacritizationDataset('data/test.csv', type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 52362\t(Train)\n",
      "        1157\t(Test)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length: {len(train_data)}\\t(Train)\\n\"\n",
    "      f\"        {len(test_data)}\\t(Test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diacritized': 'sınıf , havuz ve açık deniz çalışmalarıyla , tüm dünyada geçerli , başarılı bir standart oluşturmuştur . ',\n",
       " 'undiacritized': 'sinif , havuz ve acik deniz calismalariyla , tum dunyada gecerli , basarili bir standart olusturmustur . '}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diacritized': None,\n",
       " 'undiacritized': ' tr ekonomi ve politika haberleri turkiye nin en cesur gazetesi radikal de uye ol '}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the text by converting it to lowercase and removing any special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing text 100.00%\n",
      "Normalizing text 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Normalize the train data.\n",
    "normalize(train_data)\n",
    "\n",
    "# Normalize the test data.\n",
    "normalize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diacritized': 'sınıf havuz ve açık deniz çalışmalarıyla tüm dünyada geçerli başarılı bir standart oluşturmuştur ',\n",
       " 'undiacritized': 'sinif havuz ve acik deniz calismalariyla tum dunyada gecerli basarili bir standart olusturmustur '}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, tokenize the text by splitting it into words. We will be using Spacy for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text 6.75%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text 100.00%\n",
      "Tokenizing text 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the train data.\n",
    "tokenize(train_data)\n",
    "\n",
    "# Tokenize the test data.\n",
    "tokenize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diacritized': ['sınıf',\n",
       "  'havuz',\n",
       "  've',\n",
       "  'açık',\n",
       "  'deniz',\n",
       "  'çalışmalarıyla',\n",
       "  'tüm',\n",
       "  'dünyada',\n",
       "  'geçerli',\n",
       "  'başarılı',\n",
       "  'bir',\n",
       "  'standart',\n",
       "  'oluşturmuştur'],\n",
       " 'undiacritized': ['sinif',\n",
       "  'havuz',\n",
       "  've',\n",
       "  'acik',\n",
       "  'deniz',\n",
       "  'calismalariyla',\n",
       "  'tum',\n",
       "  'dunyada',\n",
       "  'gecerli',\n",
       "  'basarili',\n",
       "  'bir',\n",
       "  'standart',\n",
       "  'olusturmustur']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train data.\n",
    "train_data.save_data('data/train_data.pkl')\n",
    "\n",
    "# Save the test data.\n",
    "test_data.save_data('data/test_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
