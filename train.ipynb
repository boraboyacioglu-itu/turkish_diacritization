{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish Diacritisation | YZV 405E NLP Term Project\n",
    "\n",
    "Author: Bora Boyacıoğlu\n",
    "\n",
    "Student ID: 150200310\n",
    "\n",
    "## Step 2: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install unidecode --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from utils.model import Encoder, Decoder, Seq2Seq\n",
    "from utils.main_utils import build_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train dataset.\n",
    "train_dataset = pkl.load(open('data/train_data.pkl', 'rb'))\n",
    "\n",
    "# Load the test dataset.\n",
    "test_dataset = pkl.load(open('data/test_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build word to index and index to word mappings.\n",
    "vocab = {}\n",
    "vocab['w2i_und'], vocab['i2w_und'] = build_vocab(train_dataset.undiacritized)\n",
    "vocab['w2i_d'], vocab['i2w_d'] = build_vocab(train_dataset.diacritized)\n",
    "\n",
    "# Save the mappings for later use.\n",
    "with open('data/vocab.pkl', 'wb') as f:\n",
    "    pkl.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "emb_dim = 64\n",
    "hid_dim = 128\n",
    "n_layers = 2\n",
    "dropout = 0.3\n",
    "\n",
    "encoder = Encoder(input_dim=len(vocab['w2i_und']), emb_dim=emb_dim, hid_dim=hid_dim, n_layers=n_layers, dropout=dropout)\n",
    "decoder = Decoder(output_dim=len(vocab['w2i_d']), emb_dim=emb_dim, hid_dim=hid_dim, n_layers=n_layers, dropout=dropout)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab['v2i_d']['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_init = None\n",
    "\n",
    "def train(model, loader, optimizer, criterion, clip, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (src, trg) in enumerate(loader):\n",
    "        min, sec = divmod(time.time() - time_init, 60)\n",
    "        print(f\"Batch {i+1}/{len(loader)}: {(i+1)/(len(loader)):.4f}% Complete {int(min):02d}:{int(sec):02d}\", end=\"\\r\")\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # reshape to [batch size * target len, output dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch_padded = pad_sequence(src_batch, padding_value=word2idx_src[\"<pad>\"], batch_first=True)\n",
    "    trg_batch_padded = pad_sequence(trg_batch, padding_value=word2idx_trg[\"<pad>\"], batch_first=True)\n",
    "    return src_batch_padded, trg_batch_padded\n",
    "\n",
    "# Run the training process\n",
    "num_epochs = 10\n",
    "clip = 1\n",
    "\n",
    "train_dataset.to_indices('und', word2idx_src)\n",
    "train_dataset.to_indices('d', word2idx_trg)\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=18, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "time_init = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, loader, optimizer, criterion, clip, device)\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([91466, 128]) from checkpoint, the shape in current model is torch.Size([91462, 128]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([93861, 128]) from checkpoint, the shape in current model is torch.Size([93857, 128]).\n\tsize mismatch for decoder.fc_out.weight: copying a param with shape torch.Size([93861, 512]) from checkpoint, the shape in current model is torch.Size([93857, 512]).\n\tsize mismatch for decoder.fc_out.bias: copying a param with shape torch.Size([93861]) from checkpoint, the shape in current model is torch.Size([93857]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m Seq2Seq(encoder, decoder, device)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load the model's state_dict\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/e3_l8.99.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/GitHub/turkish_diacritization/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([91466, 128]) from checkpoint, the shape in current model is torch.Size([91462, 128]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([93861, 128]) from checkpoint, the shape in current model is torch.Size([93857, 128]).\n\tsize mismatch for decoder.fc_out.weight: copying a param with shape torch.Size([93861, 512]) from checkpoint, the shape in current model is torch.Size([93857, 512]).\n\tsize mismatch for decoder.fc_out.bias: copying a param with shape torch.Size([93861]) from checkpoint, the shape in current model is torch.Size([93857])."
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "emb_dim = 128\n",
    "hid_dim = 512\n",
    "n_layers = 2\n",
    "dropout = 0.3\n",
    "\n",
    "encoder = Encoder(input_dim=len(vocab['w2i_und']), emb_dim=emb_dim, hid_dim=hid_dim, n_layers=n_layers, dropout=dropout)\n",
    "decoder = Decoder(output_dim=len(vocab['w2i_d']), emb_dim=emb_dim, hid_dim=hid_dim, n_layers=n_layers, dropout=dropout)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Load the model's state_dict\n",
    "model.load_state_dict(torch.load('models/e3_l8.99.pth', map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(model, input_sentence, word2idx_src, idx2word_trg, device):\n",
    "    # Normalize and tokenize the input sentence\n",
    "    input_tokens = input_sentence.lower().split()\n",
    "    input_indices = [word2idx_src.get(token, word2idx_src['<unk>']) for token in input_tokens]\n",
    "    input_tensor = torch.tensor(input_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Encoder forward pass\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(input_tensor)\n",
    "\n",
    "    # Start decoding from the <sos> token\n",
    "    trg_indexes = [vocab['w2i_d']['<sos>']]\n",
    "    outputs = []\n",
    "\n",
    "    for i in range(50):  # Reasonable limit to sentence length\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "        \n",
    "        pred_token = output.argmax(1).item()\n",
    "        if pred_token == vocab['w2i_d']['<eos>']:  # Stop decoding at <eos>\n",
    "            break\n",
    "        outputs.append(pred_token)\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "    # Convert output indices back to words\n",
    "    translated_sentence = ' '.join([idx2word_trg[i] for i in outputs])\n",
    "    return translated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'<unk>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneden dogru ceviri yapmiyorsun?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m predicted_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw2i_und\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi2w_d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_sentence)\n",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mpredict_sentence\u001b[0;34m(model, input_sentence, word2idx_src, idx2word_trg, device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_sentence\u001b[39m(model, input_sentence, word2idx_src, idx2word_trg, device):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Normalize and tokenize the input sentence\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     input_tokens \u001b[38;5;241m=\u001b[39m input_sentence\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m----> 4\u001b[0m     input_indices \u001b[38;5;241m=\u001b[39m [word2idx_src\u001b[38;5;241m.\u001b[39mget(token, \u001b[43mword2idx_src\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<unk>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m input_tokens]\n\u001b[1;32m      5\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input_indices)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Encoder forward pass\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: '<unk>'"
     ]
    }
   ],
   "source": [
    "input_sentence = \"neden dogru ceviri yapmiyorsun?\"\n",
    "predicted_sentence = predict_sentence(model, input_sentence, vocab['w2i_und'], vocab['i2w_d'], device)\n",
    "print(\"Predicted:\", predicted_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'<unk>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw2i_und\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<unk>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: '<unk>'"
     ]
    }
   ],
   "source": [
    "vocab['w2i_und']['<unk>']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
